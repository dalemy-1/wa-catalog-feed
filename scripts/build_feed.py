import csv
import io
import os
import re
import hashlib
from decimal import Decimal, InvalidOperation

import requests

# ======================
# Config
# ======================
EXPORT_URL = os.getenv(
    "EXPORT_URL",
    "http://154.48.226.95:5001/admin/Product/export_csv",
)

# ä½ çš„æº CSV ä»·æ ¼åˆ—å
PRICE_COL = "Discount Price"

CURRENCY_BY_MARKET = {
    "US": "USD",
    "UK": "GBP",
    "DE": "EUR",
    "FR": "EUR",
    "IT": "EUR",
    "ES": "EUR",
    "CA": "CAD",
    "JP": "JPY",
}

FLAG_BY_MARKET = {
    "US": "ğŸ‡ºğŸ‡¸",
    "UK": "ğŸ‡¬ğŸ‡§",
    "DE": "ğŸ‡©ğŸ‡ª",
    "FR": "ğŸ‡«ğŸ‡·",
    "IT": "ğŸ‡®ğŸ‡¹",
    "ES": "ğŸ‡ªğŸ‡¸",
    "CA": "ğŸ‡¨ğŸ‡¦",
    "JP": "ğŸ‡¯ğŸ‡µ",
}

# Meta Feed è¾“å‡ºå­—æ®µï¼ˆåŠ å…¥ item_group_id ä¾¿äºå½’ç»„ï¼‰
OUT_FIELDS = [
    "id",
    "item_group_id",
    "title",
    "description",
    "availability",
    "condition",
    "price",
    "link",
    "image_link",
    "brand",
]


# ======================
# Helpers
# ======================
def parse_price(v) -> Decimal | None:
    """
    å…è®¸è¾“å…¥ï¼š'0', '0.00', 'Â¥99', '$19.99', '19.99 USD' ç­‰
    ä»…æŠ½å–ç¬¬ä¸€ä¸ªæ•°å­—ã€‚
    """
    if v is None:
        return None
    s = str(v).strip()
    if not s:
        return None
    s = s.replace(",", "")
    m = re.search(r"(\d+(?:\.\d+)?)", s)
    if not m:
        return None
    try:
        return Decimal(m.group(1))
    except (InvalidOperation, ValueError):
        return None


def normalize_market(market: str) -> str:
    return (market or "").strip().upper()


def normalize_asin(asin: str) -> str:
    return (asin or "").strip().upper()


def stable_unique_id(
    base_id: str,
    store: str,
    keyword: str,
    remark: str,
    link: str,
    image_url: str,
    commission: str,
    status: str,
) -> str:
    """
    ç”Ÿæˆç¨³å®šä¸”å”¯ä¸€çš„ idï¼ˆåŒä¸€è¡Œå†…å®¹æ¯æ¬¡ç”Ÿæˆéƒ½ä¸€è‡´ï¼‰ã€‚
    ä½ è¦æ±‚â€œé‡å¤é¡¹ä¿ç•™â€ï¼Œæ‰€ä»¥ä¸èƒ½è®© id é‡å¤ï¼›ç”¨å“ˆå¸Œåç¼€åŒºåˆ†æ¯ä¸€è¡Œã€‚
    """
    raw = "|".join(
        [
            base_id,
            (store or "").strip(),
            (keyword or "").strip(),
            (remark or "").strip(),
            (link or "").strip(),
            (image_url or "").strip(),
            (commission or "").strip(),
            (status or "").strip(),
        ]
    )
    suffix = hashlib.sha1(raw.encode("utf-8")).hexdigest()[:10]
    return f"{base_id}_{suffix}"


def build_rows(src_rows: list[dict]) -> list[dict]:
    out: list[dict] = []

    for src in src_rows:
        market = normalize_market(src.get("market"))
        asin = normalize_asin(src.get("asin"))

        title = (src.get("title") or "").strip()
        keyword = (src.get("keyword") or "").strip()
        store = (src.get("store") or "").strip()
        remark = (src.get("remark") or "").strip()
        link = (src.get("link") or "").strip()
        image_url = (src.get("image_url") or "").strip()

        commission = (src.get("Commission") or "").strip()
        status = (src.get("status") or "").strip()

        # åŸºæœ¬å­—æ®µæ ¡éªŒï¼šç¼ºå…³é”®å†…å®¹å°±è·³è¿‡ï¼ˆå¦åˆ™ Meta ä¹Ÿä¼šæŠ¥é”™ï¼‰
        if not market or not asin or not title or not link or not image_url:
            continue

        currency = CURRENCY_BY_MARKET.get(market, "USD")

        price_raw = src.get(PRICE_COL)
        price = parse_price(price_raw)

        # ä½ åšæŒ 0 åˆæ³•ï¼šå…è®¸ 0ï¼›å¦‚æœè§£æä¸åˆ°ï¼Œé»˜è®¤ 0
        if price is None:
            price = Decimal("0")

        # item_group_id ç”¨äºå½’ç»„ï¼ˆåŒä¸€ market+asin çš„å¤šæ¡è®°å½•å±äºåŒä¸€ç»„ï¼‰
        base_id = f"{market}_{asin}"

        unique_id = stable_unique_id(
            base_id=base_id,
            store=store,
            keyword=keyword,
            remark=remark,
            link=link,
            image_url=image_url,
            commission=commission,
            status=status,
        )

        # æ ‡é¢˜ï¼šå›½å®¶ + å›½æ—— + æ ‡é¢˜ï¼ˆæŒ‰ä½ è¦æ±‚ï¼š (CA)ğŸ‡¨ğŸ‡¦åŠ æ‹¿å¤§è“è‰²æ‹‰åŠ›å¸¦ï¼‰
        flag = FLAG_BY_MARKET.get(market, "")
        title2 = f"({market}){flag}{title}"

        # æè¿°ï¼šå›ºå®šå±•ç¤º Keyword + Storeï¼›remark ä»¥ â€œremark:xxxâ€ å½¢å¼å±•ç¤º
        lines: list[str] = []
        if keyword:
            lines.append(f"Keyword: {keyword}")
        if store:
            lines.append(f"Store: {store}")
        if remark:
            lines.append(f"remark: {remark}")

        desc = "\n".join(lines).strip()

        # è¿™é‡Œç»Ÿä¸€ç»™ in stock/newï¼ˆä½ ä¹Ÿå¯ä»¥æŒ‰ status å†³å®šï¼‰
        availability = "in stock"
        condition = "new"

        out.append(
            {
                "id": unique_id,
                "item_group_id": base_id,
                "title": title2,
                "description": desc,
                "availability": availability,
                "condition": condition,
                "price": f"{price:.2f} {currency}",
                "link": link,
                "image_link": image_url,
                "brand": store or "Generic",
            }
        )

    # æ’åºï¼šä¿ç•™é‡å¤é¡¹ï¼Œä»…è°ƒæ•´é¡ºåºï¼ˆä¸ä¼šåˆ é™¤ä»»ä½•è®°å½•ï¼‰
    out.sort(
        key=lambda r: (
            r["item_group_id"],      # market_asin å½’ç»„
            r["title"],              # æ ‡é¢˜
            r["link"],               # é“¾æ¥
            r["id"],                 # æœ€åç”¨å”¯ä¸€ id ä¿è¯ç¨³å®šæ’åº
        )
    )
    return out


def write_csv(path: str, rows: list[dict]) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8-sig", newline="") as f:
        w = csv.DictWriter(f, fieldnames=OUT_FIELDS, extrasaction="ignore")
        w.writeheader()
        for r in rows:
            w.writerow(r)


def main():
    r = requests.get(EXPORT_URL, timeout=60)
    r.raise_for_status()

    text = r.content.decode("utf-8-sig", errors="replace")
    reader = csv.DictReader(io.StringIO(text))

    fieldnames = reader.fieldnames or []
    if PRICE_COL not in fieldnames:
        raise RuntimeError(f"æ‰¾ä¸åˆ°ä»·æ ¼åˆ— '{PRICE_COL}'ï¼Œå½“å‰è¡¨å¤´: {fieldnames}")

    src_rows = list(reader)
    rows = build_rows(src_rows)

    # ä¸»æ–‡ä»¶ï¼šå…¨å›½å®¶åˆå¹¶
    write_csv("docs/meta_all.csv", rows)

    # å¯é€‰ï¼šæŒ‰ market æ‹†åˆ†ï¼ˆä¾¿äºä½ æ£€æŸ¥ï¼‰
    by_market: dict[str, list[dict]] = {}
    for row in rows:
        m = row["item_group_id"].split("_", 1)[0]
        by_market.setdefault(m, []).append(row)

    for m, mr in by_market.items():
        write_csv(f"docs/{m.lower()}.csv", mr)

    print(
        f"done: {len(rows)} rows; markets={sorted(by_market.keys())}; "
        f"example_url=docs/meta_all.csv"
    )


if __name__ == "__main__":
    main()
